out <- "/Users/johan.renaudie/Documents/Vrac/Scripts/ScienceDirect.html"
sink(out)
cat("<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">","\n")
cat("<html><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">")
cat("<style type=\"text/css\">\nbody{\nfont-family: \"Georgia\";\n}\ntable th,td{\nborder-left: thin solid;\nborder-right: thin solid;\n}\n</style>")
cat("<title>New articles</title></head>\n<body>\n<table rules=groups frame=box>\n")
cat("<thead><tr><th>Date</th><th>Journal</th><th>Title</th><th>Authors</th></tr></thead>\n<tbody>")
for(i in 1:nrow(DD)){
cat("<tr><td>",as.character(format(DD$Date[i],"%e %b %y")),"</td><td>",
as.character(DD$Journal[i]),"</td><td>","<a href=\"",
gsub("\\\"","",as.character(DD$url[i])),"\">",
as.character(DD$Title[i]),"</a></td><td>",
as.character(DD$Authors[i]),"</td></tr>\n",sep="")
if(tb[i]){cat("</tbody><tbody>")}
}
cat("</tbody></table></body></html>\n")
sink()
back <- readLines(out)
cat(gsub("<U\\+([0-9A-Z]+)>","&#x\\1;",back), sep="\n",file=out)
FC <- FC[order(FC$Date,decreasing=TRUE),]
FC <- FC[order(FC$Journal),]
tb2 <- c(FC$Journal,"")!=c("",FC$Journal)
tb2 <- tb2[-1]
out2 <- "/Users/johan.renaudie/Documents/Vrac/Scripts/Forthcoming.html"
sink(out2)
cat("<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">","\n")
cat("<html><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">")
cat("<style type=\"text/css\">\nbody{\nfont-family: \"Georgia\";\n}\ntable th,td{\nborder-left: thin solid;\nborder-right: thin solid;\n}\n</style>")
cat("<title>Forthcoming articles</title></head>\n<body>\n<table rules=groups frame=box>\n")
cat("<thead><tr><th>Date</th><th>Journal</th><th>Title</th><th>Authors</th></tr></thead>\n<tbody>")
for(i in 1:nrow(FC)){
cat("<tr><td>",as.character(format(FC$Date[i],"%e %b %y")),"</td><td>",
as.character(FC$Journal[i]),"</td><td>","<a href=\"",
gsub("\\\"","",as.character(FC$url[i])),"\">",
as.character(FC$Title[i]),"</a></td><td>",
as.character(FC$Authors[i]),"</td></tr>\n",sep="")
if(!is.na(tb[i])&tb2[i]){cat("</tbody><tbody>")}
}
cat("</tbody></table></body></html>\n")
sink()
back <- readLines(out2)
cat(gsub("<U\\+([0-9A-Z]+)>","&#x\\1;",back), sep="\n",file=out2)
out <- "ScienceDirect.html"
sink(out)
cat("<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">","\n")
cat("<html><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">")
cat("<style type=\"text/css\">\nbody{\nfont-family: \"Georgia\";\n}\ntable th,td{\nborder-left: thin solid;\nborder-right: thin solid;\n}\n</style>")
cat("<title>New articles</title></head>\n<body>\n<table rules=groups frame=box>\n")
cat("<thead><tr><th>Date</th><th>Journal</th><th>Title</th><th>Authors</th></tr></thead>\n<tbody>")
for(i in 1:nrow(DD)){
cat("<tr><td>",as.character(format(DD$Date[i],"%e %b %y")),"</td><td>",
as.character(DD$Journal[i]),"</td><td>","<a href=\"",
gsub("\\\"","",as.character(DD$url[i])),"\">",
as.character(DD$Title[i]),"</a></td><td>",
as.character(DD$Authors[i]),"</td></tr>\n",sep="")
if(tb[i]){cat("</tbody><tbody>")}
}
cat("</tbody></table></body></html>\n")
sink()
back <- readLines(out)
cat(gsub("<U\\+([0-9A-Z]+)>","&#x\\1;",back), sep="\n",file=out)
FC <- FC[order(FC$Date,decreasing=TRUE),]
FC <- FC[order(FC$Journal),]
tb2 <- c(FC$Journal,"")!=c("",FC$Journal)
tb2 <- tb2[-1]
out2 <- "Forthcoming.html"
sink(out2)
cat("<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">","\n")
cat("<html><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">")
cat("<style type=\"text/css\">\nbody{\nfont-family: \"Georgia\";\n}\ntable th,td{\nborder-left: thin solid;\nborder-right: thin solid;\n}\n</style>")
cat("<title>Forthcoming articles</title></head>\n<body>\n<table rules=groups frame=box>\n")
cat("<thead><tr><th>Date</th><th>Journal</th><th>Title</th><th>Authors</th></tr></thead>\n<tbody>")
for(i in 1:nrow(FC)){
cat("<tr><td>",as.character(format(FC$Date[i],"%e %b %y")),"</td><td>",
as.character(FC$Journal[i]),"</td><td>","<a href=\"",
gsub("\\\"","",as.character(FC$url[i])),"\">",
as.character(FC$Title[i]),"</a></td><td>",
as.character(FC$Authors[i]),"</td></tr>\n",sep="")
if(!is.na(tb[i])&tb2[i]){cat("</tbody><tbody>")}
}
cat("</tbody></table></body></html>\n")
sink()
back <- readLines(out2)
cat(gsub("<U\\+([0-9A-Z]+)>","&#x\\1;",back), sep="\n",file=out2)
install.packages("akima")
sample(1:30,16,probs=(sum(1:30)-1:30)/(sum(1:30)),replace=FALSE)
?sample
sample(1:30,16,prob=(sum(1:30)-1:30)/(sum(1:30)),replace=FALSE)
sample(1:30,16,prob=((1+sum(1:30))-1:30)/(sum(1:30)),replace=FALSE)
sample(1:30,16,prob=((1+sum(1:30))-1:30)/(sum(1:30)),replace=FALSE)
((1+sum(1:30))-1:30)/(sum(1:30))
sample(1:30,16,prob=31-1:30,replace=FALSE)
sample(1:30,16,prob=31-1:30,replace=FALSE)
sample(1:30,16,prob=31-1:30,replace=FALSE)
table(cut(sample(1:30,16,prob=31-1:30,replace=FALSE),c(0,10,20,30))
)
table(cut(sample(1:30,16,prob=31-1:30,replace=FALSE),c(0,10,20,30)))
table(cut(sample(1:30,16,prob=31-1:30,replace=FALSE),c(0,10,20,30)))
table(cut(sample(1:30,16,prob=31-1:30,replace=FALSE),c(0,10,20,30)))
table(cut(sample(1:90,64,prob=91-1:90,replace=FALSE),seq(0,90,10)))
table(cut(sample(1:90,64,prob=91-1:90,replace=FALSE),seq(0,90,10)))
table(cut(sample(1:90,64,prob=91-1:90,replace=FALSE),seq(0,90,10)))
table(cut(sample(1:90,64,prob=91-1:90,replace=FALSE),seq(0,90,10)))
table(cut(sample(1:90,64,prob=91-1:90,replace=FALSE),seq(0,90,10)))
table(cut(sample(1:90,64,prob=91-1:90,replace=FALSE),seq(0,90,10)))
table(cut(sample(1:90,64,prob=91-1:90,replace=FALSE),seq(0,90,10)))
a<-""https://www.comicsrss.com/rss/pearlsbeforeswine.rss""
a<-"https://www.comicsrss.com/rss/pearlsbeforeswine.rss"
a->feed
x<-xmlParse(getURL(feed))
library(RCurl)
library(feedeR)
x<-xmlParse(getURL(feed))
x
xpathSApply(x,"//item/title")
xpathSApply(x,"//item/title",xmlValue)
img <- xpathSApply(x,"//item/description/img",xmlAttrs)["src",]
img <- xpathSApply(x,"//item/description/img",xmlAttrs)
img
img <- xpathSApply(x,"//description/img",xmlAttrs)
img
img <- xpathSApply(x,"//description")
img
img <- xpathSApply(x,"//description/p/img",xmlAttrs)
img
xpathSApply(x,"//description/p/img",xmlAttrs)
xpathSApply(x,"//description",xmlAttrs)
xpathSApply(x,"//description")
xpathSApply(x,"//description")[[1]]
xpathSApply(x,"//item/description")[[1]]
xpathSApply(x,"//item/description",xmlValue)[[1]]
gocomics <- function(feed){
x<-xmlParse(getURL(feed))
title <- xpathSApply(x,"//item/title",xmlValue)[1]
img <- xpathSApply(x,"//item/description",xmlValue)[[1]]
c(title,img)
}
pbw <- gocomics("https://www.comicsrss.com/rss/pearlsbeforeswine.rss")
pbw
smb <- gocomics("https://www.comicsrss.com/rss/saturday-morning-breakfast-cereal.rss")
smb
xk <- feed.extract("https://xkcd.com/atom.xml")
xmlParse(getURL("https://xkcd.com/atom.xml"))
xpathSApply(xk,"//entry/summary")
xk <- xmlParse(getURL("https://xkcd.com/atom.xml"))
xpathSApply(xk,"//entry/summary")
xpathSApply(xk,"//entry")
?feed.extract
feed.extract
feedeR::parse.atom("https://xkcd.com/atom.xml")
feedeR:::parse.atom("https://xkcd.com/atom.xml")
feedeR:::parse.atom(feedeR:::feed.read("https://xkcd.com/atom.xml"))
feedeR:::parse.atom
xmlToList(xk)
xmlToList(xk)$entry
xmlToList(xk)$entry$summary$text
library(feedeR)
library(RCurl)
gocomics <- function(feed){
x<-xmlParse(getURL(feed))
title <- xpathSApply(x,"//item/title",xmlValue)[1]
img <- xpathSApply(x,"//item/description",xmlValue)[[1]]
c(title,img)
}
pbw <- gocomics("https://www.comicsrss.com/rss/pearlsbeforeswine.rss")
fk <- gocomics("https://www.comicsrss.com/rss/false-knees.rss")
p <- gocomics("https://www.comicsrss.com/rss/peanuts.rss")
smb <- gocomics("https://www.comicsrss.com/rss/saturday-morning-breakfast-cereal.rss")
xk <- xmlParse(getURL("https://xkcd.com/atom.xml"))
xkcd <- xmlToList(xk)$entry$summary$text
xkcd_tit <- xmlToList(xk)$entry$title
cat(sprintf('<html><body>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
</body></html>',
pbw[1],pbw[2],
p[1],p[2],
fk[1],fk[2]
,smbf[1],smbf[2],
xkcd_tit,xkcd),file="comics.html")
cat(sprintf('<html><body>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
</body></html>',
pbw[1],pbw[2],
p[1],p[2],
fk[1],fk[2]
,smb[1],smb[2],
xkcd_tit,xkcd),file="comics.html")
getwd()
library(feedeR)
library(RCurl)
gocomics <- function(feed){
x<-xmlParse(getURL(feed))
title <- xpathSApply(x,"//item/title",xmlValue)[1]
img <- xpathSApply(x,"//item/description",xmlValue)[[1]]
c(title,img)
}
pbw <- gocomics("https://www.comicsrss.com/rss/pearlsbeforeswine.rss")
fk <- gocomics("https://www.comicsrss.com/rss/false-knees.rss")
p <- gocomics("https://www.comicsrss.com/rss/peanuts.rss")
smb <- gocomics("https://www.comicsrss.com/rss/saturday-morning-breakfast-cereal.rss")
pdl <- gocomics("https://www.comicsrss.com/rss/poorly-drawn-lines.rss")
xk <- xmlParse(getURL("https://xkcd.com/atom.xml"))
xkcd <- xmlToList(xk)$entry$summary$text
xkcd_tit <- xmlToList(xk)$entry$title
cat(sprintf('<html><body>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
</body></html>',
pbw[1],pbw[2],
p[1],p[2],
fk[1],fk[2]
,smb[1],smb[2],
xkcd_tit,xkcd,
pdl[1],pdl[2]),file="comics.html")
toe <- xmlParse(getURL("http://www.kohney.com/feed/"))
toe
xmlToList(toe)
xmlToList(toe)$item
xpathSApply(toe,"//item/title")
xpathSApply(toe,"//item/title",xmlValue)
toe_title <- xpathSApply(toe,"//item/title",xmlValue)[1]
xpathSApply(toe,"//item/description",xmlValue)
library(feedeR)
library(RCurl)
gocomics <- function(feed){
x<-xmlParse(getURL(feed))
title <- xpathSApply(x,"//item/title",xmlValue)[1]
img <- xpathSApply(x,"//item/description",xmlValue)[[1]]
c(title,img)
}
pbw <- gocomics("https://www.comicsrss.com/rss/pearlsbeforeswine.rss")
fk <- gocomics("https://www.comicsrss.com/rss/false-knees.rss")
p <- gocomics("https://www.comicsrss.com/rss/peanuts.rss")
smb <- gocomics("https://www.comicsrss.com/rss/saturday-morning-breakfast-cereal.rss")
pdl <- gocomics("https://www.comicsrss.com/rss/poorly-drawn-lines.rss")
xk <- xmlParse(getURL("https://xkcd.com/atom.xml"))
xkcd <- xmlToList(xk)$entry$summary$text
xkcd_tit <- xmlToList(xk)$entry$title
toe <- xmlParse(getURL("http://www.kohney.com/feed/"))
toe_title <- xpathSApply(toe,"//item/title",xmlValue)[1]
toe <- xpathSApply(toe,"//item/description",xmlValue)[1]
cat(sprintf('<html><body>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
</body></html>',
pbw[1],pbw[2],
p[1],p[2],
fk[1],fk[2]
,smb[1],smb[2],
xkcd_tit,xkcd,
pdl[1],pdl[2],
toe_title, toe),file="comics.html")
toe <- xmlParse(getURL("http://www.kohney.com/feed/"))
toe
xpathSApply(toe,"//item/content:encoded",xmlValue)[1]
toe <- xmlParse(getURL("http://www.kohney.com/feed/"))
toe_title <- xpathSApply(toe,"//item/title",xmlValue)[1]
toe <- xpathSApply(toe,"//item/content:encoded",xmlValue)[1]
cat(sprintf('<html><body>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
<h2>%s</h2><br/>%s<hr/>
</body></html>',
pbw[1],pbw[2],
p[1],p[2],
fk[1],fk[2]
,smb[1],smb[2],
xkcd_tit,xkcd,
pdl[1],pdl[2],
toe_title, toe),file="comics.html")
library(feedeR)
library(RCurl)
gocomics <- function(feed){
x<-xmlParse(getURL(sprintf("https://www.comicsrss.com/rss/%s.rss",feed)))
title <- xpathSApply(x,"//item/title",xmlValue)[1]
img <- xpathSApply(x,"//item/description",xmlValue)[[1]]
sprintf("<h2>%s</h2><br/>%s<hr/>",title,img)
}
gc <- c("pearlsbeforeswine","false-knees","peanuts","saturday-morning-breakfast-cereal","poorly-drawn-lines")
xk <- xmlParse(getURL("https://xkcd.com/atom.xml"))
xkcd <- xmlToList(xk)$entry$summary$text
xkcd_tit <- xmlToList(xk)$entry$title
toe <- xmlParse(getURL("http://www.kohney.com/feed/"))
toe_title <- xpathSApply(toe,"//item/title",xmlValue)[1]
toe <- xpathSApply(toe,"//item/content:encoded",xmlValue)[1]
sink("comics.html")
cat("<html><body>")
for(i in seq_along(gc)) cat(gocomics(gc[i]))
sprintf("<h2>%s</h2><br/>%s<hr/>",xkcd_tit,xkcd)
sprintf("<h2>%s</h2><br/>%s<hr/>",toe_title, toe)
cat("</body></html>")
sink()
library(feedeR)
library(RCurl)
gocomics <- function(feed){
x<-xmlParse(getURL(sprintf("https://www.comicsrss.com/rss/%s.rss",feed)))
title <- xpathSApply(x,"//item/title",xmlValue)[1]
img <- xpathSApply(x,"//item/description",xmlValue)[[1]]
sprintf("<h2>%s</h2><br/>%s<hr/>",title,img)
}
gc <- c("pearlsbeforeswine","false-knees","peanuts","saturday-morning-breakfast-cereal","poorly-drawn-lines")
xk <- xmlParse(getURL("https://xkcd.com/atom.xml"))
xkcd <- xmlToList(xk)$entry$summary$text
xkcd_tit <- xmlToList(xk)$entry$title
toe <- xmlParse(getURL("http://www.kohney.com/feed/"))
toe_title <- xpathSApply(toe,"//item/title",xmlValue)[1]
toe <- xpathSApply(toe,"//item/content:encoded",xmlValue)[1]
sink("comics.html")
cat("<html><body>")
for(i in seq_along(gc)) cat(gocomics(gc[i]))
cat(sprintf("<h2>%s</h2><br/>%s<hr/>",xkcd_tit,xkcd))
cat(sprintf("<h2>%s</h2><br/>%s<hr/>",toe_title, toe))
cat("</body></html>")
sink()
library(RCurl)
library(XML)
gocomics <- function(feed){
x<-xmlParse(getURL(sprintf("https://www.comicsrss.com/rss/%s.rss",feed)))
title <- xpathSApply(x,"//item/title",xmlValue)[1]
img <- xpathSApply(x,"//item/description",xmlValue)[[1]]
sprintf("<h3>%s</h3><br/>%s<hr/>",title,img)
}
gc <- c("pearlsbeforeswine","false-knees","peanuts","saturday-morning-breakfast-cereal","poorly-drawn-lines")
xk <- xmlParse(getURL("https://xkcd.com/atom.xml"))
xkcd <- xmlToList(xk)$entry$summary$text
xkcd_tit <- xmlToList(xk)$entry$title
toe <- xmlParse(getURL("http://www.kohney.com/feed/"))
toe_title <- xpathSApply(toe,"//item/title",xmlValue)[1]
toe <- xpathSApply(toe,"//item/content:encoded",xmlValue)[1]
sink("comics.html")
cat("<html><body>")
for(i in seq_along(gc)) cat(gocomics(gc[i]))
cat(sprintf("<h3>%s</h3><br/>%s<hr/>",xkcd_tit,xkcd))
cat(sprintf("<h3>%s</h3><br/>%s<hr/>",toe_title, toe))
cat("</body></html>")
sink()
sink("comics.html")
cat("<html><body>")
for(i in seq_along(gc)) cat(gocomics(gc[i]))
cat(sprintf("<h2>xkcd</h2><h3>%s</h3><br/>%s<hr/>",xkcd_tit,xkcd))
cat(sprintf("<h2>The Other End</h2><h3>%s</h3><br/>%s<hr/>",toe_title, toe))
cat("</body></html>")
sink()
sink("comics.html")
cat("<html><body>")
for(i in seq_along(gc)) cat(gocomics(gc[i]))
cat(sprintf("<h2>xkcd</h2><h3>%s</h3><br/>%s<hr/>",xkcd_tit,xkcd))
cat(sprintf("<h2>The Other End</h2><h3>%s</h3><br/>%s<hr/>",toe_title, gsub("150","300",toe)))
cat("</body></html>")
sink()
bou <- xmlParse(getURL("http://www.bouletcorp.com/feed/"))
bou_title <- xpathSApply(bou,"//item/title",xmlValue)[1]
bou <- xpathSApply(bou,"//item/content:encoded",xmlValue)[1]
library(RCurl)
library(XML)
gocomics <- function(feed){
x<-xmlParse(getURL(sprintf("https://www.comicsrss.com/rss/%s.rss",feed)))
title <- xpathSApply(x,"//item/title",xmlValue)[1]
img <- xpathSApply(x,"//item/description",xmlValue)[[1]]
sprintf("<h3>%s</h3><br/>%s<hr/>",title,img)
}
gc <- c("pearlsbeforeswine","false-knees","peanuts","saturday-morning-breakfast-cereal","poorly-drawn-lines")
xk <- xmlParse(getURL("https://xkcd.com/atom.xml"))
xkcd <- xmlToList(xk)$entry$summary$text
xkcd_tit <- xmlToList(xk)$entry$title
toe <- xmlParse(getURL("http://www.kohney.com/feed/"))
toe_title <- xpathSApply(toe,"//item/title",xmlValue)[1]
toe <- xpathSApply(toe,"//item/content:encoded",xmlValue)[1]
bou <- xmlParse(getURL("http://www.bouletcorp.com/feed/"))
bou_title <- xpathSApply(bou,"//item/title",xmlValue)[1]
bou <- xpathSApply(bou,"//item/content:encoded",xmlValue)[1]
sink("comics.html")
cat("<html><body>")
for(i in seq_along(gc)) cat(gocomics(gc[i]))
cat(sprintf("<h2>xkcd</h2><h3>%s</h3><br/>%s<hr/>",xkcd_tit,xkcd))
cat(sprintf("<h2>The Other End</h2><h3>%s</h3><br/>%s<hr/>",toe_title, gsub("150","300",toe)))
cat(sprintf("<h2>Boulet</h2><h3>%s</h3><br/>%s<hr/>",bou_tit,bou))
cat("</body></html>")
sink()
sink("comics.html")
cat("<html><body>")
for(i in seq_along(gc)) cat(gocomics(gc[i]))
cat(sprintf("<h2>xkcd</h2><h3>%s</h3><br/>%s<hr/>",xkcd_tit,xkcd))
cat(sprintf("<h2>The Other End</h2><h3>%s</h3><br/>%s<hr/>",toe_title, gsub("150","300",toe)))
cat(sprintf("<h2>Boulet</h2><h3>%s</h3><br/>%s<hr/>",bou_title,bou))
cat("</body></html>")
sink()
library(RCurl)
library(XML)
gocomics <- function(feed){
x<-xmlParse(getURL(sprintf("https://www.comicsrss.com/rss/%s.rss",feed)))
title <- xpathSApply(x,"//item/title",xmlValue)[1]
img <- xpathSApply(x,"//item/description",xmlValue)[[1]]
sprintf("<h3>%s</h3><br/>%s<hr/>",title,img)
}
gc <- c("pearlsbeforeswine","false-knees","peanuts","saturday-morning-breakfast-cereal","poorly-drawn-lines","calvinandhobbes")
xk <- xmlParse(getURL("https://xkcd.com/atom.xml"))
xkcd <- xmlToList(xk)$entry$summary$text
xkcd_tit <- xmlToList(xk)$entry$title
toe <- xmlParse(getURL("http://www.kohney.com/feed/"))
toe_title <- xpathSApply(toe,"//item/title",xmlValue)[1]
toe <- xpathSApply(toe,"//item/content:encoded",xmlValue)[1]
bou <- xmlParse(getURL("http://www.bouletcorp.com/feed/"))
bou_title <- xpathSApply(bou,"//item/title",xmlValue)[1]
bou <- xpathSApply(bou,"//item/content:encoded",xmlValue)[1]
sink("comics.html")
cat("<html><body>")
for(i in seq_along(gc)) cat(gocomics(gc[i]))
cat(sprintf("<h2>xkcd</h2><h3>%s</h3><br/>%s<hr/>",xkcd_tit,xkcd))
cat(sprintf("<h2>The Other End</h2><h3>%s</h3><br/>%s<hr/>",toe_title, gsub("150","300",toe)))
cat(sprintf("<h2>Boulet</h2><h3>%s</h3><br/>%s<hr/>",bou_title,bou))
cat("</body></html>")
sink()
sink()/
871/13
??presidents
702/13
519/8
81/2.8
37*56
9000+26000+20000+34000+2700+2000
93700/2000
44088/400
110.22/60
1/ans
ans*60*24
0.544*60
?array
array(el(strsplit(input8,"")),dim=c(3,2,2))
#Day 8 Puzzle 1
input8="123456789012"
array(el(strsplit(input8,"")),dim=c(3,2,2))
t(array(el(strsplit(input8,"")),dim=c(3,2,2)))
#Day 8 Puzzle 1
input8=readLines("~/Desktop/input8.txt")
input8
nchar(input8)
nchar(input8)/25/6
im=array(as.integer(el(strsplit(input8,""))),dim=c(25,6,nchar(input8)/25/6))
apply(im,3,function(x)sum(x==0))
l0=im[,,which.min(apply(im,3,function(x)sum(x==0)))]
dim(l0)
table(l0)
table(l0)[2]*table([l0]*3)l0)[3]
sum(l0==1)*sum(l0==2)
#Day 8 Puzzle 2
m=matrix(nr=6,nc=25)
m=matrix(nr=6,nc=25)
for(i in 1:25){
for(j in 1:6){
sb=im[i,j,]
m[j,i]=head(sb[sb!=2],1)
}
}
m
image(m)
image(t(m))
image(t(m),asp=1)
image(1:6,1:25,t(m),asp=1)
image(1:25,1:6,t(m),asp=1)
image(1:25,6:1,t(m),asp=1)
image(1:25,1:6,t(m)[6:1,],asp=1)
t(m)
image(1:25,1:6,t(m)[,6:1],asp=1)
image(1:25,1:6,t(m)[,6:1],asp=1,col=c("white","black"))
image(1:25,1:6,t(m)[,6:1],asp=1,col=c("white","black"),ann=F,ax=F)
library(updateR)
install.packages("updateR")
library(installr)
install.packages("installr")
install.packages(file.choose(),type="source",repos=NULL)
setwd("~/Git/AdventOfCode2019")
#Day 25 Puzzle 1
source("intcode_fast_but_dirty.R")
code = scan("input25.tt",sep="\t")
A = intfast(code,c(),1,1,0,FALSE,FALSE)
code = scan("input25.txt",sep="\t")
code = scan("input25.txt",sep=",")
A = intfast(code,c(),1,1,0,FALSE,FALSE)
cat(A$out)
cat(rawToChar(as.Raw(A$out)))
cat(rawToChar(as.raw(A$out)))
while(A$status){
cat(rawToChar(as.raw(A$out)))
r=readline(">")
input=c(as.integer(charToRaw(r)),10)
A=intfast(A$code,input,A$n,1,A$rb,FALSE,FALSE)
}
?readline
?stdin
r=readLines()
